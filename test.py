import torch
from transformers import AutoTokenizer, AutoModelForCausalLM

# Thiáº¿t láº­p thiáº¿t bá»‹
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")

# ÄÆ°á»ng dáº«n model Ä‘Ã£ fine-tune
MODEL_PATH = "./trained_model2"

# Load tokenizer vÃ  model Ä‘Ã£ huáº¥n luyá»‡n
tokenizer = AutoTokenizer.from_pretrained(MODEL_PATH)
model = AutoModelForCausalLM.from_pretrained(MODEL_PATH).to(device)

def chat_with_model(question: str, max_new_tokens=256, temperature=0.7, top_p=0.95, top_k=50):
    """Sinh cÃ¢u tráº£ lá»i tá»« model dá»±a trÃªn cÃ¢u há»i"""
    prompt = f"Question: {question.strip()} Answer:"
    
    inputs = tokenizer(prompt, return_tensors="pt", padding=True, truncation=True).to(device)

    with torch.no_grad():
        outputs = model.generate(
            input_ids=inputs["input_ids"],
            attention_mask=inputs.get("attention_mask"),
            max_new_tokens=max_new_tokens,
            do_sample=True,
            temperature=temperature,
            top_k=top_k,
            top_p=top_p,
            no_repeat_ngram_size=3,
            repetition_penalty=1.2,
            pad_token_id=tokenizer.eos_token_id
        )

    # Giáº£i mÃ£ vÃ  trÃ­ch xuáº¥t pháº§n tráº£ lá»i
    response = tokenizer.decode(outputs[0], skip_special_tokens=True)
    answer = response.split("Answer:")[-1].strip()

    if not answer.endswith(('.', '?', '!')):
        answer += '.'

    return answer

def run_cli():
    """Giao diá»‡n trÃ² chuyá»‡n Ä‘Æ¡n giáº£n trong terminal"""
    print("ğŸ¤– Chatbot Y Táº¿ (gÃµ 'exit' Ä‘á»ƒ thoÃ¡t)\n")
    while True:
        try:
            user_input = input("ğŸ‘¤ Báº¡n: ").strip()
            if user_input.lower() in ("exit", "quit"):
                print("ğŸ‘‹ Táº¡m biá»‡t!")
                break

            if not user_input:
                print("âš ï¸ Vui lÃ²ng nháº­p cÃ¢u há»i.")
                continue

            reply = chat_with_model(user_input)
            print(f"ğŸ¤– BÃ¡c sÄ© AI: {reply}\n")
        except KeyboardInterrupt:
            print("\nğŸ‘‹ Táº¡m biá»‡t!")
            break

if __name__ == "__main__":
    run_cli()
